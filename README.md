House pricing competition
	კონკურსის მოკლე მიმოხილვა: 
		კონკურსის მთავარი ამოცანაა დავატრენინგოთ(გამოვწვრთნათ) ისეთი მოდელი, რომელიც ყველაზე უკეთ შეძლებს დაიჭიროს კანონზომიერება ცვლადებს შორის, როგორებიცაა მაგალითად გარაჟი აქვს თუ არა სახლს, სად არის სახლი ტერიტორიულად, რამდენი კვადრატულია და ა.შ. შედეგად კი შეძლოს და სწორად განსაზღვროს რა იქნება სახლის ფასი შემომავალ ინფუთზე.
	
	მიდგომა პრობლემის გადასაჭრელად: 
		ეს არის რეგრესიის ამოცანა, შესაბამისად გამოვიყენე წრფივი რეგრესიის ჩვეულებრივი მოდელი, და ასევე მისი ერთ-ერთი კონკრეტული იმპლემენტაცია(Ridge). გავაკეთე სულ სამი 		ექსპერიმენტი, თავდაპირველი ექსპერიმენტი იყო უბრალოდ ნიადაგის მოსინჯვა, feature engineering ის მხრივ არ გამომიყენებია მრავალმხრივი ტექნიქები, უბრალოდ მინდოდა მენახა 	ძალიან მარტივი მოდელი, როგორ შედეგებს დამიბრუნებდა, და თან ეს იქნებოდა კარგი ორიენტირი იმისა თუ რამდენად დიდი განვითარების პოტენციალი ჰქონდა შედეგების 	მხრივ წრფივ რეგრესიას. მომდევნო ორ მოდელში კი ბევრ ტექნიკას ვიყენებ მონაცემების დამუშავებისათვის და კანონზომიერების აღმოჩენისათვის.

რეპოზიტორიის სტრუქტურა
	ყველა ფაილის განმარტება:
     model_experiment_1: ამ ფაილში დატრენინგებული მაქვს ყველაზე მარტივი წრფივი რეგრესიის მოდელი.
     model_experiment_2_and_3: ამ ფაილში კი არის ორი მოდელი, შედარებით დახვეწილი წრფივი რეგრესიის მოდელი და ასევე Ridge.
     model_inference: აქ ხდება TEST.csv ზე დაფრედიქთება.
		
Feature Engineering
	ყველაზე მარტივ მოდელში კატეგორიულ ცვლადებს უბრალოდ დამი მნიშვნელობებს ვანიჭებდი, ხოლო უკვე გაუმჯობესებულ მოდელებში გადავწყვიტე ორნაირი დამუშავება, პირველი ეს 	არის  one-hot-encoding და მეორე target-encoding(კონკრეტულად target-mean-encoding). კატეგორიული ცვლადებისთვის შემოვიტანე threshold = 3(3 ზე ნაკლები ან ტოლი კატეგორიული 	ცვლადი თუ არის ვიყენებთ one-hot ს, 	თუარადა  target-encoding-ს). ეს threshold ის საჭიროა რადგან, ამ კონკრეტულ დატასეტში ძალიან ბევრი კატეგორიული ცვლადების ქოლუმნებია, 	შესაბამისად ყველას one-hot-ით 	დანჰენდვლა ძალიან 	ბევრ დიმენშენს გააჩნედა, და შეიძლება overfit შიც წასულიყო. target-encoding ს რაც შეეხება, საკმაოდ კარგად ასახავს 	კორელაციას კონკრეტულ კატეგორიასა და 	თარგეთს შორის, თუმცა 	სახლის ფასების შემთხვევაში რადგან ძალიან დიდ მნიშვნელობებს იღებდა ზოგი კატეგორია, გადავწყვიტე 	დამესქეილებინა, რისთვისაც StandardScaler() 	გამოვიყენე. ერთ მოდელში მხოლოდ ამ ცვლადებს ვასქეილებდი, რომელიც target-encoding ით შევცვალე, ხოლო მეორეში აბსოლიტურად 	ყველას, რათა ორივე მიდგიომა გამეტესტა. 	უშუალოდ რიცხვი სამი კარგი ბალანსის წერტილია, ახლო მიდამოში არჩეული მნიშვნელობები ვალიდაციაზე დიდ გავლენას არ ახდენდა, 	შესაბამისად დავტოვე ეს რიცხვი.
	
	
	Nan მნიშვნელობების დამუშავებას რაც შეეხება ძალიან მარტივ მოდელში უბრალოდ გადავყარე, ხოლო შედარებით უფრო დახვეწილ მოდელებში ვცადე ასეთი სვეტები ჩამენაცვლებინა 	როგორც მედიანით ასევე მოდითაც, ეს სტეპი უშუალოდ არ ჩანს კოდში, რაც ცუდია, მაგრამ  აქვე ვიტყვი რომ მოდა ვარჩიე  რადგან დიდ სხვაობას არ იძლეოდა და ძალიან ცოტათი უკეთესი 	შედეგი ჰქონდა. თავიდან მხოლოდ იმ ქოლუმნებზე გავაკეთე ეს რომელიც ტრეინში იყო Nan, ამან შექმნა რაღაც ტიპის პრობლემები, ტესტებში Nan ების არსებობის გამო, და შედარებით 	მარტივად რომ მომეგვარებინა და თან Data Leakage იც არ მქონოდა, აბსოლიტურად ყველა ქოლუმნის მოდას ვიგებდი და შემდეგ თუ Nan ველიუ ჰქონდა მაგ მოდით ვავსებდი როგორც ტრეინს 	ისე ტესტს. ამისთვის და ყველა სხვა პრეპროცესისთვის ცალ-ცალკე მაქვს შექმნილი პრეპროცესორ კლასები, რომელიც ბოლოს ფაიფლაინში მაქვს გაერთიანებული.

	ასევე ისეთი ცვლადებისთვის, რომელთაც საკმაოდ ასიმეტრიული განაწილება ჰქონდათ(skewness), დავთვალე სწორედ ამ ასიმეტრიულობის მნიშვნელობა(Skewness) არვიცი ქართულად რა 	ქვია ზუსტად, შემდეგ კი კროს ვალიდაციის დახმარებით აღმოჩნდა რომ skewness > 1 ცვლადებისთვის ლოგარითმის ამოღება და ამ ცვლადების სწორედ ამ მნიშვნელობით ჩანაცვება 	საკმაოდ კარგ შედეგს იძლეოდა. შესაბამისად ესეც უფრო დახვეწილ მოდელებზე გამოვიყენე.

Feature Selection
	ძალიან მარტივ მოდელში უბრალოდ დავტოვე ის 30 ცვლადი რომელიც სუბიექტურად მიმაჩნდა რომ დანარჩენებს შორის იყო ყველაზე მნიშვნელოვანი. დანარჩენ ორ მოდელში კი, 	კორელაციით და Ridge ის შემთხვევაში უკვე, RFE ის დახმარებით გავცხრილე ცვლადები. Ridge-ის learning rate ისთვის და ასევე RFE ცვლადების რაოდენობისთვის გამოვიყენე GRid Search, რის შედეგადაც 	საუკეთესო მოდელი დატრეინდა 50 ყველაზე მნიშვნელოვან ცვლადზე. თუმცა აღსანიშნავია ისიც, რომ საბოლოოდ ეს არ გამოდგა ყველაზე კარგი მოდელი.
	
Training
	გავტესტე სულ ორი მოდელი, ჩვეულებრივი LinearRegression და ასევე Ridge, რომელიც აუთლაიერების რეგულარიზაციას ახდენს და რადგან ისედაც უკვე ვიცოდი რომ რამოდენიმე 	აუთლაიერი წერტილი იყო, ლოგიკური იყო რომ უკეთეს შედეგს მომცემდა. ჩვეულებრივი LinearRegression ის შემთხვევაში არ გამიტესტავს მოდელის ჰიპერმარამეტრები რადგან როგორც 	დავგუგლე და ასევე დავტესტე დიდ სხვაობას არ მაძლევდა, Ridge ის შემთხვევაში კი გადავარჩიე როგორც alpha rate ისე RFE ისთვის ოპტიმალური ცვლადების რაოდენობა. მოდელის 	შეფასებისთვის ყველაზე დიდ მნიშვნელობას ვანიჭებდი RMSE სქორს. როგორც ვთქვი რადგან აუთლაიერი წერტილები გვქონდა, შედარებით უკეთესი შედეგი დადო Ridge ის მოდელმა. 	LinearRegression ს ტესტზე ჰქონდა 33155 RMSE სქორი, ხოლო Ridge ის მოდელს 32587, არც ისე დიდი სხვაობაა, რადგან ეს კონკრეტული დატასეტი დიდი საერთოდ არარის და შესაბამისად, 	ბევრი აუთლაიერ წერტილი არ გვქონია, მაგრამ დიდი დატასეტისთვის აუცილებლად მოგვცემს კარგ გაუმჯობესებას. ვალიდაციის სეტზეც average rmse score-ის უკეთესი შედეგი ჰქონდა Ridge-ს. RFE ოპტიმიზაციით მიღებულ მოდელს არ ჰქონდა დიდი სხვაობა, ძალიან ახლოს იყო ჩვეულებრივ Ridge თან, და თან ჩვეულებრივ Ridge ს უკეთესი შედეგი ჰქონდა, რაც შეიძლება იმითაც იყო გამოწვეული რომ პატარა დატასეტია და ცვლადების ამოყრამ, თან დაახლოებით 30 ცვლადი ამოვარდა, შეიძლება საკმაოდ დაგვაზიანოს ინფორმაციულობის მხრივ, ამ შემთხვევაში ახლოს იყო, და თან ჩვეულებრივი Ridge სჯობდა. შესაბამისად საბოლოო მოდელად აირჩა სწორედ ეს მოდელი.

MLflow Tracking
MLflow ექსპერიმენტების ბმული: https://dagshub.com/Luka-Surmanidze/MachineLearning.mlflow/#/experiments/3?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

მეტრიკები რომელიც გამოვიყენე არის MAE, MSE, RMSE, MAPE და R2. აქედან ყველაზე დიდ მნიშვნელობას ცხადია ვანიჭებდი RMSE, რადგან მისი მათემატიკური იმპლემენტაციიდან გამომდინარე ყველაზე სენსიტიურია დიდი ერორების მიმართ. რადგან MAE დიდ ერორს კარგად ვერ იჭერდა, ვერც MAPE(რომელიც უბრალოდ პროცენტული რეპრეზენტაციია mea absolute error ის) და R2. 

საუკეთესო მოდელის შედეგები
best_RMSE_score 32314.809655254154

test_mae 20359.872282118464
test_mape 0.1201204388255124
test_mse 1061965580.285634
test_rmse 32587.813370731612

train_mae 18592.316302271855
train_mape 0.1086879873387551
train_mse 813305848.1619654
train_rmse 28518.51763612487

როგორც ვხედავთ ტრეინის და ტესტის RMSE დაახლოებით 4000 ით განსხვავდება, რაც გარკვეულწილად არის overfit თუმცა რომ ვთქვათ რომ რაღაც ექსტრემალური სიტუაციაა არა. რადგან ვალიდაციის RMSE საკმაოდ ახლოს არის ტესტისასთან, შეგვიძლია ისიც ვთქვათ, რომ მოდელი საკმაოდ კარგად ანზოგადებს კანონზომიერებას, და კროს ვალიდაციაციის დროს მიღებული RMSE  საკმაოდ ეფექტური მეტრიკაა ამის შესაფასებლად. RMSE სა და MAE ს შორის ვხედავთ რომ საკმაოდ დიდი ერორია, რაც გვაფიქრებინებს იმას რომ არის რაღაც წერტილები, რომლებზედაც ერორი ისევ საკმაოდ დიდია. საბოლოო ჯამში კი შეგვიძლია ვთქვათ რომ მოდელი საკმაოდ სტაბილურია, თუმცა ალბათ ცოტათი underfit იც არის რადგან train ზე 28k ერორი საკმაოდ ბევრია მაინც.
